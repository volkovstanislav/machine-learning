{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Для конвейера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import calendar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from time import sleep\n",
    "from joblib import Parallel, delayed\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Установка параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Системные\n",
    "warnings.filterwarnings(action = 'ignore') #не выводим предупреждающие сигналы\n",
    "pd.options.display.max_columns = 500 #максимальное кол-во колонок для отображения в блокноте\n",
    "pd.options.display.max_rows = 500 #максимальное кол-во колонок для отображения в блокноте\n",
    "pd.options.display.width = 1000 #ширина окна\n",
    "\n",
    "# Расчетные\n",
    "njobs = -1 # Количество используемых ядер (используем все)\n",
    "days_ = 365 # Количество дней из паспорта продукта \n",
    "Type = '10' # Тип продукта из паспорта продукта\n",
    "start = dt.datetime.now().date() - dt.timedelta(days=1) #Дата оформления заявки (application_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Модуль БКИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт данных и первичная обработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт шаблона CRE\n",
    "df_main =  pd.read_csv(os.getenv('DATA'), sep = ';' , converters = {'inn' : str , 'inn_con':str, 'OPENDATE' : str ,\n",
    "                                                 'FACTCLOSEDATE' : str , 'PMTSTRINGSTART' : str ,\n",
    "                                                 'FINALPMTDATE' : str, 'PMTSTRING84M' : str, \n",
    "                                                 'TYPE_': str})\n",
    "df_main[\"application_date\"] = start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Импорт шаблона CRE\n",
    "# df_main =  pd.read_csv(r'C:\\Users\\VOLKOV_STAN\\Documents\\Projects\\module_bki\\pacl100.csv', sep = ';' , converters = {'inn' : str , 'inn_con':str, 'OPENDATE' : str ,\n",
    "#                                                  'FACTCLOSEDATE' : str , 'PMTSTRINGSTART' : str ,\n",
    "#                                                  'FINALPMTDATE' : str, 'PMTSTRING84M' : str, \n",
    "#                                                  'TYPE_': str})\n",
    "# df_main[\"application_date\"] = start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Доработка, связанная с открытой датой договора\n",
    "def cor_day(day):\n",
    "    if (day > 0) & (day < 10):\n",
    "        return '0' + str(day)\n",
    "    else:\n",
    "        return str(day)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# доработка связанная с тем что конвейер зачем то заполняет фактическую дату закрытия (есть вероятность , \n",
    "# что при текущей доработки при действительном закрытии договора на сегодня он проставится как открытый, но это очень маловероятно)\n",
    "df_main['FACTCLOSEDATE'] = df_main['FACTCLOSEDATE'].apply(lambda date : 'NaT' if date == (cor_day(start.day) + cor_day(start.month) + str(start.year)) else date)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для корректировки ИНН\n",
    "def corr_inn(x): \n",
    "    if len(x) == 11 or len(x) == 9: \n",
    "        return '0' + x\n",
    "    else: \n",
    "        return x\n",
    "    \n",
    "df_main['inn'] = df_main['inn'].apply(corr_inn)\n",
    "df_main['inn_con'] = df_main['inn_con'].apply(corr_inn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для приведения даты к нужному формату\n",
    "def OPEN_(x): \n",
    "    if len(x) == 7:\n",
    "        return '0' + x\n",
    "    else: \n",
    "        return x \n",
    "df_main['OPENDATE'] = df_main['OPENDATE'].apply(OPEN_)\n",
    "df_main['FACTCLOSEDATE'] = df_main['FACTCLOSEDATE'].apply(OPEN_)\n",
    "df_main['PMTSTRINGSTART'] = df_main['PMTSTRINGSTART'].apply(OPEN_)\n",
    "df_main['FINALPMTDATE'] = df_main['FINALPMTDATE'].apply(OPEN_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем вспомогательные поля \n",
    "df = df_main.drop_duplicates()\n",
    "df.drop(['ul_flag'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    291\n",
       "1     53\n",
       "Name: ul_flag, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Формируем флаг ЮЛ или ИП и связанное ФЛ \n",
    "def ul_flag_(x):\n",
    "    if len(x) == 10: \n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "    \n",
    "df['ul_flag'] = df['inn_con'].apply(ul_flag_)\n",
    "df[\"ul_flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Корректировка платежной строки\n",
    "# Удаляем символ подчеркивания в начале платежной строки \n",
    "df['PMTSTRING84M'] = df['PMTSTRING84M'].apply(lambda x : x[1:] if str(x) != 'nan' and '_' in x else x)\n",
    "\n",
    "# Замена символов B,C на A\n",
    "def replace_symbol_rev(x):\n",
    "    for i in x:\n",
    "        if i in ('B', 'C'):\n",
    "             x = x.replace(i, 'A')\n",
    "    return x\n",
    "\n",
    "df['PMTSTRING84M'] = df['PMTSTRING84M'].apply(replace_symbol_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ качества данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для приведения типов данных всех столбцов в датафрейме к типу Object\n",
    "def df_dtype_to_obj(df):\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].astype(object)\n",
    "    return df\n",
    "\n",
    "# Функция перевода даты к нужному формату \n",
    "def to_date(x):\n",
    "    if str(x) in ('NA', 'nan', 'NaT'):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return dt.date(int(x[4:]), int(x[2:4]), int(x[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замена пустот на пропуски\n",
    "df = df.replace('', np.nan)\n",
    "\n",
    "# Фильтр на записи с неизвестным качеством платежей\n",
    "df = df[(df.PMTSTRING84M.isin(['NA', 'nan', np.nan, 'NaT']) == False)]\n",
    "\n",
    "# Фильтр на записи с неизвестными датами открытия\n",
    "df = df[( \n",
    "    (df.OPENDATE.astype('str').isin(['NA', 'nan', np.nan, 'NaT']) | df.OPENDATE.isnull()) == False)]\n",
    "\n",
    "# Приводим даты к формату (YYYY-MM-DD)\n",
    "columns = ['OPENDATE','FACTCLOSEDATE','PMTSTRINGSTART','FINALPMTDATE']\n",
    "\n",
    "for col in columns: \n",
    "    df[col] = df[col].apply(to_date) \n",
    "    \n",
    "# Длина платежной строки\n",
    "df['len_PMTSTRING84M'] = df.PMTSTRING84M.astype('str').apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убираем банковские займы, 24 продукт, кредит мобильного оператора  \n",
    "delete_obj = lambda x : x in ('18', '15', '24')\n",
    "df = df.iloc[np.where(df['TYPE_'].apply(delete_obj) == False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Расчет стоп-факторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стоп-фактор (90+ или более) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вспомогательные расчеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Находим минимальную дату по клиенту\n",
    "df_f = df.groupby(['inn_con'], as_index=False)['OPENDATE'].min().rename(columns = {'OPENDATE' : 'OPENDATE_min'})\n",
    "df = df.merge(df_f , how = 'inner', on = ['inn_con'])\n",
    "\n",
    "# Удаление вспомогательного DataFrame\n",
    "del df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспомогательные таблицы для всех факторов \n",
    "inn_list = df['inn_con'].unique().tolist()\n",
    "df = df.set_index(['inn_con']).sort_index()\n",
    "\n",
    "OPENDATE = df.reset_index()[['inn_con', 'application_date']].drop_duplicates().set_index(['inn_con'])\n",
    "OPENDATE_min = df.reset_index()[['inn_con', 'OPENDATE_min']].drop_duplicates().set_index(['inn_con'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем были ли символы дефолтов в платежной строке:\n",
    "# 4 - Просрочка 90-119, 5 - >120, 9 - Безнадежный долг / Передано на взыскание\n",
    "df['has_def'] = df['PMTSTRING84M'].apply(lambda x : 1 if ('4' in x) or ('5' in x) or ('9' in x) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для простановки даты для дефолтников \n",
    "def def_date(has_def, pmtstring, opendate):\n",
    "    if has_def == 0:\n",
    "        return None\n",
    "    else : \n",
    "        delta = re.search(r'[459]' , pmtstring[::-1]).start()\n",
    "        return opendate + dt.timedelta(delta*30)\n",
    "    \n",
    "# Функция для рассчета стоп фактора \n",
    "def has_stop(inn, df, opendate_df, opendate_min):\n",
    "    df = df.drop(['inn'], axis = 1).drop_duplicates()\n",
    "    res = []\n",
    "    for opendate in opendate_df['application_date']:\n",
    "        if opendate == opendate_min: \n",
    "            res.append({'inn_con': inn, 'opendate': opendate, 'value': 0})\n",
    "        else: \n",
    "            var = df[(df['OPENDATE'] <= opendate) & (df['def_date'].astype(str) != 'None')]['has_def'].max()\n",
    "            if np.isnan(var) : \n",
    "                res.append({'inn_con': inn, 'opendate': opendate, 'value': 0})\n",
    "            else : \n",
    "                res.append({'inn_con': inn, 'opendate': opendate, 'value': var})\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Расчет стоп-фактора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  55 | elapsed:    4.2s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    4.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Дата дефолта\n",
    "df['def_date'] = list(map(def_date, df['has_def'], df['PMTSTRING84M'], df['OPENDATE']))\n",
    "\n",
    "df = df_dtype_to_obj(df)\n",
    "OPENDATE = df_dtype_to_obj(OPENDATE)\n",
    "\n",
    "has_stop_df =  pd.concat(Parallel(verbose=True, max_nbytes=None, n_jobs=njobs)(\n",
    "    delayed(has_stop)(inn, df.loc[[inn]], OPENDATE.loc[[inn]], OPENDATE_min.loc[inn].tolist()[0]) for inn in inn_list))\n",
    "\n",
    "df.drop(['has_def', 'def_date'], axis = 1 , inplace = True)\n",
    "\n",
    "# Разворачиваем стоп - фактор \n",
    "has_stop_90 = has_stop_df.rename(columns = {'opendate': 'application_date', 'value': 'stop_has_90'})\n",
    "\n",
    "# Merge с исходной таблицей \n",
    "df = df.merge(has_stop_90, how = 'inner', on = ['inn_con', 'application_date'])\n",
    "\n",
    "# Удаление вспомогательных табличек \n",
    "del has_stop_90 \n",
    "del has_stop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отдельные флаги для каждого уровня связи\n",
    "for i in range(3):\n",
    "    df['stop_has_90_lvl'+str(i)] = np.where((df['con_lvl']==i) & (df['stop_has_90']==1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Находим максимальный флаг на уровне клиента\n",
    "df_f = df.groupby('inn', as_index=False).agg({'stop_has_90_lvl0':'max', 'stop_has_90_lvl1':'max', 'stop_has_90_lvl2':'max'})\n",
    "df = df.drop(['stop_has_90_lvl0','stop_has_90_lvl1','stop_has_90_lvl2'],axis=1).merge(df_f, on='inn', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим общий флаг\n",
    "df.drop('stop_has_90', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cтоп-фактор количество кредитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ошибка в расчёте\n",
    "# # Кол-во кредитов для клиента и связанных лиц\n",
    "# for i in range(3):\n",
    "#     df_count = df[df['con_lvl'] == i].drop_duplicates()\\\n",
    "#                                             .groupby(['inn_con'], as_index = False)\\\n",
    "#                                             .agg({'OPENDATE' : 'count'})\\\n",
    "#                                             .rename(columns = {'OPENDATE' : 'stop_count_cred_lvl'+str(i)})\n",
    "#     # Merge с исходной таблицей \n",
    "#     df = df.merge(df_count, how = 'left', on = ['inn_con'])\n",
    "#     df['stop_count_cred_lvl'+str(i)].fillna(0, inplace=True)\n",
    "#     del df_count\n",
    "    \n",
    "# Кол-во кредитов для клиента и связанных лиц\n",
    "for i in range(3):\n",
    "    df_count = df[df['con_lvl'] == i]\\\n",
    "                                    .groupby(['inn','inn_con'], as_index = False)\\\n",
    "                                    .agg({'OPENDATE' : 'count'})\\\n",
    "                                    .rename(columns = {'OPENDATE' : 'stop_count_cred_lvl'+str(i)})\n",
    "    # Merge с исходной таблицей \n",
    "    df = df.merge(df_count, how = 'left', on = ['inn','inn_con'])\n",
    "    df['stop_count_cred_lvl'+str(i)].fillna(0, inplace=True)\n",
    "    del df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Находим максимальный флаг на уровне клиента\n",
    "df_f = df.groupby('inn', as_index=False).agg({'stop_count_cred_lvl0':'max', 'stop_count_cred_lvl1':'max', 'stop_count_cred_lvl2':'max'})\n",
    "df = df.drop(['stop_count_cred_lvl0','stop_count_cred_lvl1','stop_count_cred_lvl2'],axis=1).merge(df_f, on='inn', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cтоп-фактор текущая просрочка "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняем пропуски по текущей просрочки \n",
    "df.fillna({'CURRENTDELQ': 0} , inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считаем максимальную по заемщику\n",
    "df_current = df.groupby(['inn_con'], as_index =False)['CURRENTDELQ'].max()\n",
    "df.drop(['CURRENTDELQ'], axis = 1 , inplace = True)\n",
    "df = df.merge(df_current, how = 'inner', on = ['inn_con'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отдельные флаги для каждого уровня связи\n",
    "for i in range(3):\n",
    "    df['stop_CURRENTDELQ_max_lvl'+str(i)] = np.where(df['con_lvl']==i, df['CURRENTDELQ'], 0)\n",
    "\n",
    "df.drop('CURRENTDELQ', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Находим максимальный флаг на уровне клиента\n",
    "df_f = df.groupby('inn', as_index=False).agg({'stop_CURRENTDELQ_max_lvl0':'max', 'stop_CURRENTDELQ_max_lvl1':'max', 'stop_CURRENTDELQ_max_lvl2':'max'})\n",
    "df = df.drop(['stop_CURRENTDELQ_max_lvl0','stop_CURRENTDELQ_max_lvl1','stop_CURRENTDELQ_max_lvl2'],axis=1).merge(df_f, on='inn', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cтоп-факторы Количество просрочек 1-29, 30-59 и 60-89 за 2 года"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вспомогательные расчеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 340 out of 340 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Формирование таблицы платежей из платежной строки\n",
    "def get_payment_table(df = None):\n",
    "    txt = df['PMTSTRING84M'][::-1]\n",
    "    tmp_table = []\n",
    "    \n",
    "    for j in range(len(txt)):\n",
    "            date = df['OPENDATE']+ relativedelta(months=j)\n",
    "            tmp_table.append([df['inn_con'], df['OPENDATE'], date, txt[j]])               \n",
    "    return pd.DataFrame(tmp_table, columns=['inn_con', 'OPENDATE', 'date','PMTSTRING84M'])\n",
    "\n",
    "# Пробегаемся по всем Dataframe\n",
    "columns1 = ['inn_con', 'OPENDATE',  'PMTSTRING84M']\n",
    "\n",
    "# Таблица платежей \n",
    "payment_table = pd.concat(\n",
    "    Parallel(n_jobs = njobs, verbose = True)(delayed(get_payment_table)(row)\n",
    "                                             for _, row in df.reset_index()[columns1].drop_duplicates().iterrows()), ignore_index = True)\n",
    "# payment_table = payment_table.merge(range_df , how = 'inner', on = ['PMTSTRING84M']).set_index(['inn_con'])\n",
    "payment_table = payment_table.set_index(['inn_con'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Расчет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция расчета кол-во просрочек A, 2, 3 в течени \n",
    "def cnt_dpd(inn, payment_table_inn, opendate_df, opendate_min):\n",
    "    res = []\n",
    "    for opendate in opendate_df['application_date']:\n",
    "             for dpd in ['A','2','3']:\n",
    "                for day in [365*2]: \n",
    "                    date_edge = opendate - dt.timedelta(day)\n",
    "                    if opendate == opendate_min:\n",
    "                        res.append({'inn_con': inn, 'opendate': opendate, 'value': np.nan, 'dpd': dpd, 'days': day})\n",
    "                    else : \n",
    "                        flag = list(payment_table_inn[(payment_table_inn['date'] <= opendate) & (payment_table_inn['date'] > date_edge)]['PMTSTRING84M'].values)\n",
    "                        if flag == []:\n",
    "                            res.append({'inn_con': inn, 'opendate': opendate, 'value': 0, 'dpd': dpd, 'days': day})\n",
    "                        else:\n",
    "                            res.append({'inn_con': inn, 'opendate': opendate, 'value': flag.count(dpd), 'dpd': dpd, 'days': day})\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  55 | elapsed:    1.7s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "payment_table = df_dtype_to_obj(payment_table)\n",
    "OPENDATE = df_dtype_to_obj(OPENDATE)\n",
    "cnt_dpd_df =  pd.concat(Parallel(verbose=True, max_nbytes=None, n_jobs=njobs)(\n",
    "        delayed(cnt_dpd)(inn, payment_table.loc[[inn]], OPENDATE.loc[[inn]], OPENDATE_min.loc[inn].tolist()[0]) for inn in inn_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разворот таблицы\n",
    "cnt_dpd_df = pd.pivot_table(cnt_dpd_df, values = ['value'], columns = ['dpd', 'days'], index = ['inn_con', 'opendate'])\n",
    "cnt_dpd_df.columns = cnt_dpd_df.columns.droplevel()\n",
    "\n",
    "# Переименование столбцов\n",
    "new_cols = []\n",
    "for col in cnt_dpd_df.columns:\n",
    "    new_cols.append('stop_cnt_dpd_'+str(col[0])+'_'+str(col[1]))\n",
    "cnt_dpd_df.columns = new_cols\n",
    "cnt_dpd_df = cnt_dpd_df.reset_index().drop(['opendate'],axis=1)\n",
    "\n",
    "# Мэтчим с основными данными \n",
    "df = df.merge(cnt_dpd_df, how='left', on='inn_con')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считаем максимальную просрочку на клиенте по связанным лицам 0-ого уровня\n",
    "df_lvl0 = df[df['con_lvl']==0][['inn', 'stop_cnt_dpd_2_730', 'stop_cnt_dpd_3_730', 'stop_cnt_dpd_A_730']]\\\n",
    "    .drop_duplicates()\\\n",
    "    .groupby('inn', as_index=False)\\\n",
    "    .agg({'stop_cnt_dpd_2_730' : 'max', 'stop_cnt_dpd_3_730' : 'max', 'stop_cnt_dpd_A_730' : 'max'})\\\n",
    "    .rename(columns={'stop_cnt_dpd_2_730' : 'stop_cnt_dpd_2_730_max_lvl0', 'stop_cnt_dpd_3_730' : 'stop_cnt_dpd_3_730_max_lvl0', 'stop_cnt_dpd_A_730' : 'stop_cnt_dpd_A_730_max_lvl0'}) \n",
    "\n",
    "# Мэтчим с основными данными на уровне клиента\n",
    "df = df.merge(df_lvl0, how='left', on='inn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считаем максимальную просрочку на клиенте по связанным лицам 1-ого уровня\n",
    "df_lvl1 = df[df['con_lvl']==1][['inn', 'stop_cnt_dpd_2_730', 'stop_cnt_dpd_3_730', 'stop_cnt_dpd_A_730']]\\\n",
    "    .drop_duplicates()\\\n",
    "    .groupby('inn', as_index=False)\\\n",
    "    .agg({'stop_cnt_dpd_2_730' : 'max', 'stop_cnt_dpd_3_730' : 'max', 'stop_cnt_dpd_A_730' : 'max'})\\\n",
    "    .rename(columns={'stop_cnt_dpd_2_730' : 'stop_cnt_dpd_2_730_max_lvl1', 'stop_cnt_dpd_3_730' : 'stop_cnt_dpd_3_730_max_lvl1', 'stop_cnt_dpd_A_730' : 'stop_cnt_dpd_A_730_max_lvl1'}) \n",
    "\n",
    "# Мэтчим с основными данными на уровне клиента\n",
    "df = df.merge(df_lvl1, how='left', on='inn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считаем максимальную просрочку на клиенте по связанным лицам 2-ого уровня\n",
    "df_lvl2 = df[df['con_lvl'] == 2][['inn', 'stop_cnt_dpd_2_730', 'stop_cnt_dpd_3_730', 'stop_cnt_dpd_A_730']]\\\n",
    "    .drop_duplicates()\\\n",
    "    .groupby('inn', as_index=False)\\\n",
    "    .agg({'stop_cnt_dpd_2_730' : 'max', 'stop_cnt_dpd_3_730' : 'max', 'stop_cnt_dpd_A_730' : 'max'})\\\n",
    "    .rename(columns={'stop_cnt_dpd_2_730' : 'stop_cnt_dpd_2_730_max_lvl2','stop_cnt_dpd_3_730' : 'stop_cnt_dpd_3_730_max_lvl2', 'stop_cnt_dpd_A_730' : 'stop_cnt_dpd_A_730_max_lvl2'}) \n",
    "\n",
    "# Мэтчим с основными данными на уровне клиента\n",
    "df = df.merge(df_lvl2, how='left', on='inn')\n",
    "\n",
    "# Удаляем промежуточные таблицы\n",
    "del cnt_dpd_df, payment_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формируем итоговую таблицу со стоп-факторами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Стоп факторы по Клиенту (ИП и ЮЛ):**\n",
    "- *stop_CURRENTDELQ_max_lvl0* - Максимальная текущая просрочка на дату актуальности\n",
    "- *stop_cnt_dpd_2_730_max_lvl0* и *stop_cnt_dpd_3_730_max_lvl0* - Максимум длительности просрочки за 2 года более 29 дней\n",
    "- *stop_count_cred_lvl0* - Кол-во взятых кредитов по клиенту больше 25\n",
    "- *stop_has_90_lvl0* - Наличие у клиента просрочки 90+\n",
    "\n",
    "**Стоп факторы по связанным ФЛ 1-ого уровня:**\n",
    "- *stop_CURRENTDELQ_max_lvl1* - Максимальная текущая просрочка на дату актуальностимна уровне связанного лица\n",
    "- *stop_cnt_dpd_3_730_max_lvl1* - Максимум длительности просрочки за 2 года (>59 дней) на уровне связанного лица\n",
    "- *stop_cnt_dpd_2_730_max_lvl1* - Кол-во просрочек 30-59 за 2 года у связанного клиента (> 1) \n",
    "- *stop_count_cred_lvl1* - Кол-во взятых кредитов по связанным лицам 1-ого уровня больше 25 договоров\n",
    "- *stop_cnt_dpd_A_730_max_lvl1* - Кол-во просрочек 1-29 более 20 у связанного с клиентом лица\n",
    "- *stop_has_90_lvl1* - Если у связанного с клиентом лица были просрочки 90+\n",
    "\n",
    "**Стоп факторы по связанным ФЛ 2-ого уровня:**\n",
    "- *stop_CURRENTDELQ_max_lvl2* -  Максимальная текущая просрочка на дату актуальности на уровне связанного лица\n",
    "- *stop_cnt_dpd_3_730_max_lvl2* - Максимум длительности просрочки за 2 года (>59 дней) на уровне связанного лица\n",
    "- *stop_cnt_dpd_2_730_max_lvl2* - Если у связанного клиента кол-во просрочек 30-59 за года больше 1 \n",
    "- *stop_count_cred_lvl2* - Кол-во взятых кредитов по связанным лицам 1-ого уровня больше 25 договоров\n",
    "- *stop_has_90_lvl2* - Если у связанного с клиентом лица были просрочки 90+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка таблицы со стоп-факторами\n",
    "df_stop = df.drop(['inn_con', 'con_lvl', 'PMTSTRING84M','TYPE_', 'OPENDATE', 'FACTCLOSEDATE','PMTSTRINGSTART','FINALPMTDATE','application_date','ul_flag','len_PMTSTRING84M','OPENDATE_min','stop_cnt_dpd_2_730', 'stop_cnt_dpd_3_730','stop_cnt_dpd_A_730'], axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stop['ul_flag'] = df_stop['inn'].apply(ul_flag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для проставления стоп-факторов для ЮЛ\n",
    "def stop_ul(row):\n",
    "    stop_answer_ul = ''\n",
    "    if row['ul_flag'] == 1:\n",
    "        if row['stop_has_90_lvl0'] > 0:\n",
    "            stop_answer_ul = stop_answer_ul + 'Кол-во просрочек 90+ по клиенту' + ' | '\n",
    "        if row['stop_has_90_lvl1'] > 0:\n",
    "            stop_answer_ul = stop_answer_ul + 'Кол-во просрочек 90+ по связанным 1-ого уровня' + ' | '\n",
    "        if row['stop_has_90_lvl2'] > 0:\n",
    "            stop_answer_ul = stop_answer_ul + 'Кол-во просрочек 90+ по связанным 2-ого уровня' + ' | '\n",
    "        if row['stop_count_cred_lvl0'] > 25:\n",
    "            stop_answer_ul = stop_answer_ul + 'Кол-во кредитов более 25 по клиенту' + ' | '\n",
    "        if row['stop_count_cred_lvl1'] > 25:\n",
    "            stop_answer_ul = stop_answer_ul + 'Кол-во кредитов более 25 по связанным 1-ого уровня' + ' | '\n",
    "        if row['stop_count_cred_lvl2'] > 25:\n",
    "            stop_answer_ul = stop_answer_ul + 'Кол-во кредитов более 25 по связанным 2-ого уровня' + ' | '\n",
    "        if row['stop_CURRENTDELQ_max_lvl0'] > 0:\n",
    "            stop_answer_ul = stop_answer_ul + 'Максимальная текущая просрочка на дату актуальности по клиенту' + ' | '\n",
    "        if row['stop_CURRENTDELQ_max_lvl1'] > 0:\n",
    "            stop_answer_ul = stop_answer_ul + 'Максимальная текущая просрочка на дату актуальности по связанным 1-ого уровня ' + ' | '\n",
    "        if row['stop_CURRENTDELQ_max_lvl2'] > 0:\n",
    "            stop_answer_ul = stop_answer_ul + 'Максимальная текущая просрочка на дату актуальности по связанным 2-ого уровня ' + ' | '\n",
    "        if (row['stop_cnt_dpd_2_730_max_lvl0'] > 0) | (row['stop_cnt_dpd_3_730_max_lvl0'] > 0):\n",
    "            stop_answer_ul = stop_answer_ul + 'Максимальная текущая просрочка за 2 года (>29 дней) по клиенту' + ' | '\n",
    "        if row['stop_cnt_dpd_2_730_max_lvl1'] > 1:\n",
    "            stop_answer_ul = stop_answer_ul + 'Максимальное кол-во просрочек 30-59 за 2 года больше одного по связанным 1-ого уровня' + ' | '\n",
    "        if row['stop_cnt_dpd_2_730_max_lvl2'] > 1:\n",
    "            stop_answer_ul = stop_answer_ul + 'Максимальное кол-во просрочек 30-59 за 2 года больше одного по связанным 2-ого уровня' + ' | '\n",
    "        if row['stop_cnt_dpd_3_730_max_lvl1'] > 0:\n",
    "            stop_answer_ul = stop_answer_ul + 'Максимальная текущая просрочка за 2 года (>59 дней) по связанным 1-ого уровня' + ' | '\n",
    "        if row['stop_cnt_dpd_3_730_max_lvl2'] > 0:\n",
    "            stop_answer_ul = stop_answer_ul + 'Максимальная текущая просрочка за 2 года (>59 дней) по связанным 2-ого уровня' + ' | '\n",
    "        if row['stop_cnt_dpd_A_730_max_lvl1'] > 20:\n",
    "            stop_answer_ul = stop_answer_ul + 'Кол-во просрочек 1-29 за 2 года по связанным 1-ого уровня' + ' | '\n",
    "\n",
    "    if len(stop_answer_ul) == 0:\n",
    "        return stop_answer_ul\n",
    "    else:\n",
    "        return 'СТОП ЮЛ: ' + stop_answer_ul\n",
    "\n",
    "# Применяем функцию\n",
    "df_stop['stop_ul_name'] = df_stop.apply(stop_ul, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для проставления стоп-факторов для ИП\n",
    "def stop_ip(row):\n",
    "    stop_answer_ip = ''\n",
    "    if row['ul_flag'] == 0:\n",
    "        if row['stop_has_90_lvl0'] > 0:\n",
    "            stop_answer_ip = stop_answer_ip + 'Кол-во просрочек 90+ по клиенту' + ' | '\n",
    "        if row['stop_count_cred_lvl0'] > 25:\n",
    "            stop_answer_ip = stop_answer_ip + 'Кол-во кредитов более 25 по клиенту' + ' | '\n",
    "        if row['stop_CURRENTDELQ_max_lvl0'] > 0:\n",
    "            stop_answer_ip = stop_answer_ip + 'Максимальная текущая просрочка на дату актуальности по клиенту' + ' | '\n",
    "        if (row['stop_cnt_dpd_2_730_max_lvl0'] > 0) | (row['stop_cnt_dpd_3_730_max_lvl0'] > 0):\n",
    "            stop_answer_ip = stop_answer_ip + 'Максимальная текущая просрочка за 2 года (>29 дней) по клиенту' + ' | '\n",
    "            \n",
    "    if len(stop_answer_ip) == 0:\n",
    "        return stop_answer_ip\n",
    "    else:\n",
    "        return 'СТОП ИП: ' + stop_answer_ip\n",
    "\n",
    "# Применяем функцию\n",
    "df_stop['stop_ip_name'] = df_stop.apply(stop_ip, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция ненулевой строки\n",
    "def not_empty(string):\n",
    "    if len(string) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Проставляем финальные стопы по факторам для ЮЛ и связям 1-ого и 2-ого уровня\n",
    "df_stop['stop_bki_ul'] = df_stop['stop_ul_name'].apply(not_empty)\n",
    "\n",
    "# Проставляем финальные стопы по факторам для ИП\n",
    "df_stop['stop_bki_ip'] = df_stop['stop_ip_name'].apply(not_empty)\n",
    "\n",
    "# Проставляем финальные стоп-флаг для последюущего использования в стэкинге\n",
    "df_stop['stop_bki_final'] = np.where(df_stop['stop_bki_ip'] + df_stop['stop_bki_ul'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем стоп-факторы\n",
    "df_stop = df_stop[['inn',\n",
    "              'stop_has_90_lvl0', 'stop_has_90_lvl1','stop_has_90_lvl2', \n",
    "              'stop_count_cred_lvl0', 'stop_count_cred_lvl1', 'stop_count_cred_lvl2',\n",
    "              'stop_CURRENTDELQ_max_lvl0', 'stop_CURRENTDELQ_max_lvl1', 'stop_CURRENTDELQ_max_lvl2',\n",
    "              'stop_cnt_dpd_2_730_max_lvl0', 'stop_cnt_dpd_3_730_max_lvl0', 'stop_cnt_dpd_A_730_max_lvl0',\\\n",
    "              'stop_cnt_dpd_2_730_max_lvl1', 'stop_cnt_dpd_3_730_max_lvl1', 'stop_cnt_dpd_A_730_max_lvl1', \n",
    "              'stop_cnt_dpd_2_730_max_lvl2', 'stop_cnt_dpd_3_730_max_lvl2', 'stop_cnt_dpd_A_730_max_lvl2', \n",
    "              'stop_ul_name', 'stop_ip_name', 'stop_bki_ip', 'stop_bki_ul', 'stop_bki_final']]\\\n",
    "            .drop_duplicates().reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Расчет факторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_dtype_to_obj(df)\n",
    " \n",
    "# Исключение записей, в которых дата начала платежной строки позже даты оформления заявки \n",
    "df = df[df['PMTSTRINGSTART'] <= df[\"application_date\"]] \n",
    "\n",
    "# Исключение записей, в которых дата открытия позже планируемой даты закрытия  \n",
    "df = df[df['FINALPMTDATE'] >= df['OPENDATE']]\n",
    "\n",
    "# Исключение записей, в которых дата открытия больше фактической даты закрытия\n",
    "df = df[(df['FACTCLOSEDATE'] < df['OPENDATE']) == False]\n",
    "\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для проверки даты\n",
    "check_fdate = lambda x : x <= dt.datetime.strptime('2050-01-01', '%Y-%m-%d').date()\n",
    "\n",
    "# Для проверки принадлежности продукта к КК \n",
    "check_type_kk = lambda x : x in ('7', '8') \n",
    "\n",
    "# Убираем те продукты для которых невозможно большое значение финальной даты платежа \n",
    "df = df.iloc[np.where(((df['FINALPMTDATE'].apply(check_fdate) == True) & (df['TYPE_'].apply(check_type_kk) == False)) \n",
    "                       | ((df['TYPE_'].apply(check_type_kk) == True)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление договоров с некорректной датой открытия\n",
    "check_opn_date = lambda x: (x[0] < dt.datetime.strptime('1990-01-01', '%Y-%m-%d').date()) | (x[0] > x[1])\n",
    "\n",
    "df = df.iloc[np.where(df[['OPENDATE','application_date']].apply(check_opn_date, axis = 1) == False)]\n",
    "\n",
    "# корректировка фактической даты закрытия (если превышает 2019)\n",
    "def check_fact_close_date(x):\n",
    "    try:\n",
    "        np.isnan(x[0])\n",
    "        \n",
    "        return True\n",
    "    except:\n",
    "        if  x[0] > x[1]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "df.iloc[\n",
    "    np.where(df[['FACTCLOSEDATE','application_date']].apply(check_fact_close_date, axis = 1) == True)[0], \n",
    "    np.where(df.columns == 'FACTCLOSEDATE')[0]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Год и месяц открытия займа\n",
    "df['OPENDATE_ym'] = df['OPENDATE'].astype('str').str[:7]\n",
    "\n",
    "# Год и месяц факт. закрытия\n",
    "df['FACTCLOSEDATE_ym'] = df['FACTCLOSEDATE'].astype('str').str[:7]\n",
    "\n",
    "# Год и месяц теор. закрытия контракта\n",
    "df['FINALPMTDATE_ym'] = df['FINALPMTDATE'].astype('str').str[:7]\n",
    "\n",
    "# Год и месяц начала строки платежей\n",
    "df['PMTSTRINGSTART_ym'] =  df['PMTSTRINGSTART'].astype('str').str[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приводим к формату\n",
    "df = df_dtype_to_obj(df)\n",
    "\n",
    "# Фильтр на 'дата открытия не позже даты первого символа' \n",
    "df = df[df['OPENDATE'] <= df['PMTSTRINGSTART']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исключаем записи где длина платежной строки не совпадает с разницой между датой открытия и PMTSTRINGSTART\n",
    "def diff_month(start, open):\n",
    "    return (start.year*12 + start.month - open.year*12 - open.month + 1)\n",
    "\n",
    "df['test1'] = list(map(diff_month , df['PMTSTRINGSTART'], df['OPENDATE']))\n",
    "df['my_int'] = (df.test1 == df['len_PMTSTRING84M'] ).astype('int64')\n",
    "\n",
    "df = df[df['my_int'] ==1]\n",
    "\n",
    "# Удаляем вспомогательные поля \n",
    "df.drop(['my_int', 'test1'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление дубликатов \n",
    "df = df.groupby(['inn','inn_con','con_lvl','PMTSTRING84M','TYPE_',\\\n",
    "            'ul_flag','len_PMTSTRING84M','OPENDATE_ym',\\\n",
    "            'FACTCLOSEDATE_ym','FINALPMTDATE_ym','PMTSTRINGSTART_ym'], as_index= False)\\\n",
    "            ['OPENDATE', 'FACTCLOSEDATE', 'PMTSTRINGSTART', \"application_date\", 'FINALPMTDATE'].agg('min')\n",
    "df.drop(['OPENDATE_ym','FACTCLOSEDATE_ym','FINALPMTDATE_ym','PMTSTRINGSTART_ym'], axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# замена непонятных символов на X \n",
    "def replace_symbol(x):\n",
    "    for i in x: \n",
    "        if i not in ('0', '1', '2', '3', '4', '5', '7', '8', '9', 'A', 'X'): \n",
    "             x = x.replace(i, 'X')\n",
    "    return x\n",
    "\n",
    "df['PMTSTRING84M'] = df['PMTSTRING84M'].apply(replace_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление предодобряемого кредита \n",
    "# Вспомогательная запись, при рассчете в конвейере это просто дата подача заявки, и параметры продукта из паспорта \n",
    "tmp_df = df[df['con_lvl']==0][[\"inn\",\"application_date\"]].drop_duplicates()\n",
    "\n",
    "tmp_df['inn_con'] = tmp_df[\"inn\"]\n",
    "tmp_df['con_lvl'] = 0\n",
    "tmp_df[\"PMTSTRING84M\"] = \"\"\n",
    "tmp_df[\"TYPE_\"] = Type\n",
    "tmp_df[\"ul_flag\"] = np.nan\n",
    "tmp_df[\"len_PMTSTRING84M\"] = 0\n",
    "tmp_df[\"OPENDATE\"] = tmp_df[\"application_date\"]\n",
    "tmp_df[\"FACTCLOSEDATE\"] = np.nan\n",
    "tmp_df[\"PMTSTRINGSTART\"] = np.nan\n",
    "tmp_df[\"FINALPMTDATE\"] = tmp_df[\"application_date\"] + dt.timedelta(days_)\n",
    "\n",
    "df = df.append(tmp_df)\n",
    "del tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Находим минимальную дату по заемщику\n",
    "df['OPENDATE'] = pd.to_datetime(df['OPENDATE'])\n",
    "df_f = df.groupby(['inn_con'], as_index=False)['OPENDATE'].min().rename(columns= {'OPENDATE':'OPENDATE_min'})\n",
    "df = df.merge(df_f , how = 'inner', on = ['inn_con'])\n",
    "del df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспомогательные таблицы для всех факторов \n",
    "inn_list = df['inn_con'].unique().tolist()\n",
    "df = df.set_index(['inn_con']).sort_index()\n",
    "\n",
    "OPENDATE = df.reset_index()[['inn_con', 'application_date']].drop_duplicates().set_index(['inn_con'])\n",
    "OPENDATE_min = df.reset_index()[['inn_con', 'OPENDATE_min']].drop_duplicates().set_index(['inn_con'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фактор - Длительность кредитной истории в месяцах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приводим к правильному формату\n",
    "df[\"OPENDATE_min\"] = pd.to_datetime(df[\"OPENDATE_min\"])\n",
    "df['application_date'] = pd.to_datetime(df['application_date'])\n",
    "df['FACTCLOSEDATE'] = pd.to_datetime(df['FACTCLOSEDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Длительность кредитной истории в месяцах\n",
    "def month_len(open_date , min_date):\n",
    "    if str(min_date) == 'nan':\n",
    "        return 0\n",
    "    else :\n",
    "        return round((open_date - min_date).days/30)\n",
    "    \n",
    "# Рассчет\n",
    "df['cred_hist'] = list(map( month_len, df['application_date'], df['OPENDATE_min']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вспомогательные рассчеты для других факторов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспомогательные таблицы для всех факторов \n",
    "inn_list = df.reset_index()['inn_con'].unique().tolist()\n",
    "#df = df.set_index(['inn_con']).sort_index()\n",
    "\n",
    "OPENDATE = df.reset_index()[['inn_con', 'application_date']].drop_duplicates().set_index(['inn_con'])\n",
    "OPENDATE_min = df.reset_index()[['inn_con', 'OPENDATE_min']].drop_duplicates().set_index(['inn_con'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фактор  - Количество месяцев с открытия последнего кредита"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество месяцев с открытия последнего кредита к текущей дате  \n",
    "def cnt_from_last(inn, df, opendate_df, opendate_min):\n",
    "    df = df.drop(['inn'], axis = 1).drop_duplicates()\n",
    "    res = []\n",
    "    for opendate in  opendate_df['application_date']:\n",
    "        max_date = df[(df['OPENDATE'] < opendate)]['OPENDATE'].max()\n",
    "        if str(max_date) == 'nan':\n",
    "            res.append({'inn_con': inn, 'opendate': opendate, 'value': np.nan})\n",
    "        else :\n",
    "            res.append({'inn_con': inn, 'opendate': opendate, 'value': round((opendate - max_date).days/30)})\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "# Расчет\n",
    "df = df_dtype_to_obj(df)\n",
    "OPENDATE = df_dtype_to_obj(OPENDATE)    \n",
    "cnt_month_from_last = pd.concat(Parallel(verbose=True, max_nbytes=None, n_jobs= njobs)(\n",
    "    delayed(cnt_from_last)(inn, df.loc[[inn]], OPENDATE.loc[[inn]], OPENDATE_min.loc[inn].tolist()[0]) for inn in inn_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фактор - Количество кредитов взятых на дату по продуктам 7 и 9 за 1-2 года"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для рассчета продукта \n",
    "def cnt_prod(inn, df, opendate_df, opendate_min): # days, product\n",
    "    df = df.drop(['inn','con_lvl'], axis = 1).drop_duplicates()\n",
    "    res = []\n",
    "    for opendate in opendate_df['application_date']:\n",
    "        for product in [\"9\", \"7\"]:\n",
    "            for days in [365, 365*2]: \n",
    "                #отсчитываем дату, насколько отступать\n",
    "                date_edge = opendate - dt.timedelta(days)\n",
    "                if opendate == opendate_min: \n",
    "                    res.append({'inn_con': inn, 'opendate': opendate, 'value': 1, 'product': product, 'days': days}) \n",
    "                else :\n",
    "                    value = df[(df['OPENDATE'] <= opendate) & (df['OPENDATE'] > date_edge) & (df['TYPE_'] == product)].shape[0]\n",
    "                    res.append({'inn_con': inn, 'opendate': opendate, 'value': value, 'product': product, 'days': days})\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  55 | elapsed:    1.8s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "df = df_dtype_to_obj(df)\n",
    "OPENDATE = df_dtype_to_obj(OPENDATE) \n",
    "cnt_prod_df =  pd.concat(Parallel(verbose=True, max_nbytes=None, n_jobs=njobs)(\n",
    "    delayed(cnt_prod)(inn, df.loc[[inn]], OPENDATE.loc[[inn]], OPENDATE_min.loc[inn].tolist()[0]) for inn in inn_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фактор - Количество полученных кредитов за последние 12/24 месяцев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество полученных кредитов в последние 1-2 года\n",
    "def cnt_receive(inn, df, opendate_df, opendate_min):\n",
    "    df = df.drop(['inn','con_lvl'], axis = 1).drop_duplicates()\n",
    "    res = []\n",
    "    for opendate in opendate_df['application_date']:\n",
    "        for day in [365, 365*2]:\n",
    "            #отсчитываем дату , насколько отступать\n",
    "            date_edge = opendate - dt.timedelta(day)\n",
    "            if opendate == opendate_min: \n",
    "                res.append({'inn_con': inn, 'opendate': opendate, 'value': 1, 'days': day})\n",
    "            else :\n",
    "                value = df[(df['OPENDATE'] <= opendate) & (df['OPENDATE'] > date_edge)].shape[0]\n",
    "                res.append({'inn_con': inn, 'opendate': opendate, 'value': value, 'days': day})\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  55 | elapsed:    1.9s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Рассчет фактора по дням \n",
    "df = df_dtype_to_obj(df)\n",
    "OPENDATE = df_dtype_to_obj(OPENDATE) \n",
    "cnt_receive_df =  pd.concat(Parallel(verbose=True, max_nbytes=None, n_jobs=njobs)(\n",
    "        delayed(cnt_receive)(inn, df.loc[[inn]], OPENDATE.loc[[inn]], OPENDATE_min.loc[inn].tolist()[0]) for inn in inn_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фактор - Количество активных кредитов за последние 3/6/12  месяцев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество активных кредитов за последние 3/6/12/24  месяцев\n",
    "def cnt_active(inn, df, opendate_df, opendate_min):\n",
    "    df = df.drop(['inn','con_lvl'], axis = 1).drop_duplicates()\n",
    "    res = []\n",
    "    for opendate in opendate_df['application_date']:\n",
    "         for day in [90, 180, 365]:\n",
    "            #отсчитываем дату, насколько отступать\n",
    "            date_edge = opendate - dt.timedelta(day)\n",
    "            if opendate == opendate_min: \n",
    "                res.append({'inn_con': inn, 'opendate': opendate, 'value': 1, 'days': day})\n",
    "            else :\n",
    "                value = df[(df['OPENDATE'] <= opendate) & ((df['FACTCLOSEDATE'].astype(str) == 'nan') | (df['FACTCLOSEDATE'].astype(str) == 'NaT') | (df['FACTCLOSEDATE'] > date_edge))].shape[0]\n",
    "                res.append({'inn_con': inn, 'opendate': opendate, 'value': value, 'days': day})\n",
    "    return pd.DataFrame(res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  55 | elapsed:    1.7s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Рассчет фактора \n",
    "df = df_dtype_to_obj(df)\n",
    "OPENDATE = df_dtype_to_obj(OPENDATE)\n",
    "cnt_active_df =  pd.concat(Parallel(verbose=True, max_nbytes=None, n_jobs=njobs)(\n",
    "    delayed(cnt_active)(inn, df.loc[[inn]], OPENDATE.loc[[inn]], OPENDATE_min.loc[inn].tolist()[0]) for inn in inn_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сколько раз за последние 3/6/12/24 месяца клиент уходил в 1+dpd, 30+dpd и 60+dpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 341 out of 341 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Еще раз разворачиваем платежную строку\n",
    "payment_table = pd.concat(\n",
    "    Parallel(n_jobs = njobs, verbose = True)(delayed(get_payment_table)(row)\n",
    "                                             for _, row in df.reset_index()[columns1].drop_duplicates().iterrows()), ignore_index = True)\n",
    "payment_table = payment_table.set_index(['inn_con'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество выходов в просрочку 30+ и 60+ и 1+ pf 3/6/12/24 месяца\n",
    "def cnt_dpd(inn, payment_table_inn, opendate_df, opendate_min):\n",
    "    res = []\n",
    "    for opendate in opendate_df['application_date']:\n",
    "             for dpd in ['2', '3', 'A']:\n",
    "                for  day in [90, 180, 365, 365*2]: \n",
    "                    date_edge = opendate - dt.timedelta(day)\n",
    "                    if opendate == opendate_min:\n",
    "                        res.append({'inn_con': inn, 'opendate': opendate, 'value': np.nan, 'dpd': dpd, 'days': day})\n",
    "                    else : \n",
    "                        flag = list(payment_table_inn[(payment_table_inn['date'] <= opendate) & (payment_table_inn['date'] > date_edge)]['PMTSTRING84M'].values)\n",
    "                        if flag == []:\n",
    "                            res.append({'inn_con': inn, 'opendate': opendate, 'value': 0, 'dpd': dpd, 'days': day})\n",
    "                        else:\n",
    "                            res.append({'inn_con': inn, 'opendate': opendate, 'value': flag.count(dpd), 'dpd': dpd, 'days': day})\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  55 | elapsed:    1.8s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "payment_table = df_dtype_to_obj(payment_table)\n",
    "OPENDATE = df_dtype_to_obj(OPENDATE) \n",
    "cnt_dpd_df =  pd.concat(Parallel(verbose=True, max_nbytes=None, n_jobs=njobs)(\n",
    "        delayed(cnt_dpd)(inn, payment_table.loc[[inn]], OPENDATE.loc[[inn]], OPENDATE_min.loc[inn].tolist()[0]) for inn in inn_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединяем таблицы c расчетами факторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Разворот таблицы c фактором кол-во кредитов по продуктам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_prod_df = pd.pivot_table(cnt_prod_df, values = ['value'], columns = ['product', 'days'], index = ['inn_con', 'opendate'])\n",
    "cnt_prod_df.columns = cnt_prod_df.columns.droplevel()\n",
    "\n",
    "# Переименование столбцов\n",
    "new_cols = []\n",
    "for col in cnt_prod_df.columns:\n",
    "    new_cols.append('cnt_prod_'+str(col[0])+'_'+str(col[1]))\n",
    "cnt_prod_df.columns = new_cols\n",
    "\n",
    "cnt_prod_df.reset_index(inplace=True)\n",
    "cnt_prod_df.rename(columns = { 'opendate': 'application_date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разворот таблицы с факторами просрочек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разворот таблицы\n",
    "cnt_dpd_df = pd.pivot_table(cnt_dpd_df, values = ['value'], columns = ['dpd', 'days'], index = ['inn_con', 'opendate'])\n",
    "cnt_dpd_df.columns = cnt_dpd_df.columns.droplevel()\n",
    "\n",
    "# Переименование столбцов\n",
    "new_cols = []\n",
    "for col in cnt_dpd_df.columns:\n",
    "    new_cols.append('cnt_dpd_'+str(col[0])+'_'+str(col[1]))\n",
    "cnt_dpd_df.columns = new_cols\n",
    "\n",
    "cnt_dpd_df.reset_index(inplace=True)\n",
    "cnt_dpd_df.rename(columns = { 'opendate': 'application_date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разворот таблицы с фактором общего кол-ва кредитов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разворот таблицы\n",
    "cnt_receive_df = pd.pivot_table(cnt_receive_df, values = ['value'], columns = ['days'], index = ['inn_con', 'opendate'])\n",
    "cnt_receive_df.columns = cnt_receive_df.columns.droplevel()\n",
    "\n",
    "# Переименование столбцов\n",
    "new_cols = []\n",
    "for col in cnt_receive_df.columns:\n",
    "    new_cols.append('cnt_receive_'+str(col))\n",
    "cnt_receive_df.columns = new_cols\n",
    "\n",
    "cnt_receive_df.reset_index(inplace=True)\n",
    "cnt_receive_df.rename(columns = { 'opendate': 'application_date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разворот таблицы с фактором общего кол-ва активных договоров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разворот таблицы\n",
    "cnt_active_df = pd.pivot_table(cnt_active_df, values = ['value'], columns = ['days'], index = ['inn_con', 'opendate'])\n",
    "cnt_active_df.columns = cnt_active_df.columns.droplevel()\n",
    "\n",
    "# Переименование столбцов\n",
    "new_cols = []\n",
    "for col in cnt_active_df.columns:\n",
    "    new_cols.append('cnt_active_'+str(col))\n",
    "cnt_active_df.columns = new_cols\n",
    "\n",
    "cnt_active_df.reset_index(inplace=True)\n",
    "cnt_active_df.rename(columns = { 'opendate': 'application_date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Готовим таблицу для фактора \"Количество месяцев от взятия последнего кредита\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переименовываем\n",
    "cnt_month_from_last.rename(columns={'value':'cnt_month_from_last', 'opendate': 'application_date'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Объединение таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['len_PMTSTRING84M', 'ul_flag'], axis=1).drop_duplicates().reset_index()\n",
    "df['application_date'] = pd.to_datetime(df['application_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединение таблиц\n",
    "df = df.reset_index().merge(cnt_month_from_last, on = ['inn_con', 'application_date'])\\\n",
    "                     .merge(cnt_prod_df, on = ['inn_con', 'application_date'])\\\n",
    "                     .merge(cnt_dpd_df, on = ['inn_con', 'application_date'])\\\n",
    "                     .merge(cnt_receive_df, on = ['inn_con', 'application_date'])\\\n",
    "                     .merge(cnt_active_df, on = ['inn_con', 'application_date'])\n",
    "\n",
    "df.drop(['PMTSTRING84M', 'TYPE_', 'OPENDATE','FACTCLOSEDATE', 'PMTSTRINGSTART',\t'FINALPMTDATE', 'OPENDATE_min', 'index'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление расчтеных таблиц и дубликатов\n",
    "del cnt_month_from_last, cnt_prod_df, cnt_receive_df, cnt_active_df, cnt_dpd_df \n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Факторы для связанных лиц 1-ого уровня"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Максимальное кол-во просрочек 1-29 (А) среди связанных лиц 1-ого уровня за 6 месяцев\n",
    "- Максимальное кол-во активных кредитов среди связанных лиц 1-ого уровня за 1 год\n",
    "- Суммарное кол-во взятых потребительских кредитов среди связанных лиц 1-ого уровня за 1 год"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>con_lvl</th>\n",
       "      <th>inn</th>\n",
       "      <th>cred_hist</th>\n",
       "      <th>cnt_month_from_last</th>\n",
       "      <th>cnt_prod_7_365</th>\n",
       "      <th>cnt_prod_7_730</th>\n",
       "      <th>cnt_prod_9_365</th>\n",
       "      <th>cnt_prod_9_730</th>\n",
       "      <th>cnt_dpd_2_90</th>\n",
       "      <th>cnt_dpd_2_180</th>\n",
       "      <th>cnt_dpd_2_365</th>\n",
       "      <th>cnt_dpd_2_730</th>\n",
       "      <th>cnt_dpd_3_90</th>\n",
       "      <th>cnt_dpd_3_180</th>\n",
       "      <th>cnt_dpd_3_365</th>\n",
       "      <th>cnt_dpd_3_730</th>\n",
       "      <th>cnt_dpd_A_90</th>\n",
       "      <th>cnt_dpd_A_180</th>\n",
       "      <th>cnt_dpd_A_365</th>\n",
       "      <th>cnt_dpd_A_730</th>\n",
       "      <th>cnt_receive_365</th>\n",
       "      <th>cnt_receive_730</th>\n",
       "      <th>cnt_active_90</th>\n",
       "      <th>cnt_active_180</th>\n",
       "      <th>cnt_active_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7840052590</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7839499175</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7840056940</td>\n",
       "      <td>140</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7840068568</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>7839495389</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index con_lvl         inn cred_hist  cnt_month_from_last  cnt_prod_7_365  cnt_prod_7_730  cnt_prod_9_365  cnt_prod_9_730  cnt_dpd_2_90  cnt_dpd_2_180  cnt_dpd_2_365  cnt_dpd_2_730  cnt_dpd_3_90  cnt_dpd_3_180  cnt_dpd_3_365  cnt_dpd_3_730  cnt_dpd_A_90  cnt_dpd_A_180  cnt_dpd_A_365  cnt_dpd_A_730  cnt_receive_365  cnt_receive_730  cnt_active_90  cnt_active_180  cnt_active_365\n",
       "0      0       1  7840052590        33                   33               0               0               0               0             0              0              0              0             0              0              0              0             0              0              0              0                0                0              1               1               1\n",
       "1      1       1  7839499175        55                   55               0               0               0               0             0              0              0              0             0              0              0              0             0              0              0              0                0                0              0               0               0\n",
       "2      2       1  7840056940       140                   29               0               0               0               0             0              0              0              0             0              0              0              0             1              1              2              2                0                0              1               1               1\n",
       "3      5       1  7840068568       103                    1               0               4               8               9             0              3              6              6             0              1              3              3             4             11             30             39               11               16              8              12              17\n",
       "4     25       1  7839495389        94                    1               1               1               2               2             0              0              0              0             0              0              0              0             0              0              0              0                3                3              4               6               6"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Формируем таблицу для рассчета факторов \n",
    "df1 = df[df['con_lvl'] == 1].drop(['inn_con','application_date'], axis = 1).reset_index()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считаем фаткоры для связей 1-ого уровня\n",
    "df1 = df1.groupby(['inn', 'con_lvl'],as_index = False)\\\n",
    ".agg({'cnt_dpd_A_180' : 'max', 'cnt_active_365' : 'max', 'cnt_prod_9_365' : 'sum'})\\\n",
    ".rename(columns={'cnt_dpd_A_180' : 'cnt_dpd_A_180_max_lvl1', 'cnt_active_365' : 'cnt_active_365_max_lvl1', 'cnt_prod_9_365' : 'cnt_prod_9_365_sum_lvl1'})\n",
    "\n",
    "df1['application_date'] = start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стоп-факторы для связанных лиц 2-ого уровня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['con_lvl']==2][['inn', 'con_lvl']].merge(df_stop[['inn', 'stop_CURRENTDELQ_max_lvl2','stop_cnt_dpd_3_730_max_lvl2',\\\n",
    "                        'stop_cnt_dpd_2_730_max_lvl2','stop_count_cred_lvl2', 'stop_has_90_lvl2','stop_ul_name', 'stop_ip_name',\\\n",
    "                        'stop_bki_ip', 'stop_bki_ul', 'stop_bki_final']], on='inn', how='inner')\n",
    "df2['application_date'] = start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разделяем выборки на ИП, ЮЛ и связанные лица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем флаг для определения ИП / ЮЛ\n",
    "df['ul_flag'] = df['inn_con'].apply(ul_flag_)\n",
    "\n",
    "# Уровень заемщика\n",
    "df = df[df['con_lvl'] == 0]\n",
    "\n",
    "# Разбивка исходную табличку на ИП и ЮЛ \n",
    "df_ul = df[df['ul_flag'] == 1]\n",
    "df_ip = df[df['ul_flag'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итоговый скор по модели ИП"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Список факторов для модели ИП:**\n",
    "- *cred_hist* - Длительность кредитной истории\n",
    "- *cnt_month_from_last* - Количество месяцев от взятие последнего кредита\n",
    "- *cnt_prod_7_730* - Количество взятых кредитных карт за 2 года\n",
    "- *cnt_receive_730* - Количество кредитов за 2 года\n",
    "- *cnt_dpd_A_90* - Количество просрочек 1-29 за 3 месяца\n",
    "- *cnt_dpd_A_730* - Количество просрочек 1-29 за 2 года"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основные параметры WOE трансформации\n",
    "bucket_summary = pd.DataFrame.from_dict(\n",
    "    {'feature_name': {0: 'cnt_dpd_2_730',  \n",
    "                      1: 'cnt_dpd_2_730',  \n",
    "                      2: 'cnt_dpd_2_730',  \n",
    "                      3: 'cnt_dpd_2_730',  \n",
    "                      4: 'cnt_dpd_A_730',  \n",
    "                      5: 'cnt_dpd_A_730', \n",
    "                      6: 'cnt_dpd_A_730',  \n",
    "                      7: 'cnt_dpd_A_730',  \n",
    "                      8: 'cnt_dpd_A_730',  \n",
    "                      9: 'cnt_dpd_A_90',  \n",
    "                      10: 'cnt_dpd_A_90',  \n",
    "                      11: 'cnt_dpd_A_90',  \n",
    "                      12: 'cnt_month_from_last',  \n",
    "                      13: 'cnt_month_from_last',  \n",
    "                      14: 'cnt_month_from_last',  \n",
    "                      15: 'cnt_month_from_last',  \n",
    "                      16: 'cnt_month_from_last',  \n",
    "                      17: 'cnt_month_from_last',  \n",
    "                      18: 'cnt_month_from_last',  \n",
    "                      19: 'cnt_month_from_last',  \n",
    "                      20: 'cnt_month_from_last',  \n",
    "                      21: 'cnt_month_from_last',  \n",
    "                      22: 'cnt_prod_7_730',  \n",
    "                      23: 'cnt_prod_7_730',  \n",
    "                      24: 'cnt_prod_7_730',  \n",
    "                      25: 'cnt_prod_7_730',  \n",
    "                      26: 'cnt_receive_730',  \n",
    "                      27: 'cnt_receive_730',  \n",
    "                      28: 'cnt_receive_730', \n",
    "                      29: 'cnt_receive_730',  \n",
    "                      30: 'cnt_receive_730',  \n",
    "                      31: 'cnt_receive_730',  \n",
    "                      32: 'cred_hist',  \n",
    "                      33: 'cred_hist',  \n",
    "                      34: 'cred_hist',  \n",
    "                      35: 'cred_hist',  \n",
    "                      36: 'cred_hist',  \n",
    "                      37: 'cred_hist',  \n",
    "                      38: 'cred_hist'}, \n",
    "     'bin_idx': {\n",
    "         0: 0,  1: 1,  2: 2,  3: 3,  \n",
    "         4: 0,  5: 1,  6: 2,  7: 3,  8: 4,  \n",
    "         9: 0,  10: 1,  11: 2,  \n",
    "         12: 0,  13: 1,  14: 2,  15: 3,  16: 4,  17: 5,  18: 6,  19: 7,  20: 8,  21: 9,  \n",
    "         22: 0,  23: 1,  24: 2,  25: 3,  \n",
    "         26: 0,  27: 1,  28: 2,  29: 3,  30: 4,  31: 5,  \n",
    "         32: 0,  33: 1,  34: 2,  35: 3,  36: 4,  37: 5,  38: 6}, \n",
    "     'left': {\n",
    "         0: 0.0,  1: 0.5,  2: 1.5,  3: 2.5,  \n",
    "         4: 0.0,  5: 0.5,  6: 2.5,  7: 5.5,  8: 9.5,  \n",
    "         9: 0.0,  10: 0.5,  11: 1.5,  \n",
    "         12: 0.0,  13: 0.5,  14: 1.5,  15: 2.5,  16: 3.5,  17: 5.5,  18: 9.5,  19: 15.5,  20: 21.5,  21: 36.5,  \n",
    "         22: 0.0,  23: 0.5,  24: 1.5,  25: 2.5,  26: 1.0,  27: 1.5,  28: 2.5,  29: 4.5,  30: 5.5,  31: 7.5, \n",
    "         32: 0.0,  33: 8.5,  34: 22.5,  35: 31.5,  36: 43.5,  37: 62.5,  38: 107.5}, \n",
    "     'right_incl': {\n",
    "         0: 0.5,  1: 1.5,  2: 2.5,  3: 15.0,  \n",
    "         4: 0.5,  5: 2.5,  6: 5.5,  7: 9.5,  8: 101.0,  \n",
    "         9: 0.5,  10: 1.5,  11: 28.0,  \n",
    "         12: 0.5,  13: 1.5,  14: 2.5,  15: 3.5,  16: 5.5,  17: 9.5,  18: 15.5,  19: 21.5,  20: 36.5,  21: 191.0,  \n",
    "         22: 0.5,  23: 1.5,  24: 2.5,  25: 15.0, 26: 1.5,  27: 2.5,  28: 4.5,  29: 5.5,  30: 7.5,  31: 31.0,  \n",
    "         32: 8.5,  33: 22.5,  34: 31.5,  35: 43.5,  36: 62.5,  37: 107.5,  38: 241.0}, \n",
    "     'WOE': {\n",
    "         0: -0.1880088318970106,  \n",
    "         1: 1.140908871703087,  \n",
    "         2: 1.390451282935173,  \n",
    "         3: 2.082116021068431,  \n",
    "         4: -0.8099897567938716,  \n",
    "         5: -0.04458560251203465,  \n",
    "         6: 0.5391768386315199,  \n",
    "         7: 0.8418973025974247,  \n",
    "         8: 1.365888895032022,  \n",
    "         9: -0.5866946449965996,  \n",
    "         10: 0.6831553898033805,  \n",
    "         11: 1.535895603429139,  \n",
    "         12: 0.9493704265080174,  \n",
    "         13: 0.7729859205737548,  \n",
    "         14: 0.4695522477478746,  \n",
    "         15: 0.2909067729491971,  \n",
    "         16: 0.06880121494737351,  \n",
    "         17: -0.1891854102186834,  \n",
    "         18: -0.5356111160795217,  \n",
    "         19: -0.703032385973634,  \n",
    "         20: -1.131183848373461,  \n",
    "         21: -1.420833245930525,  \n",
    "         22: -0.4311140053635858,  \n",
    "         23: -0.1378549241807703,  \n",
    "         24: 0.2938371528273737,  \n",
    "         25: 1.043458213387425,  \n",
    "         26: -1.340041348385566,  \n",
    "         27: -0.622331186416715,  \n",
    "         28: -0.1936957038382362,  \n",
    "         29: 0.1944897765237562,  \n",
    "         30: 0.5941197331040289,  \n",
    "         31: 1.647806867259153,  \n",
    "         32: 0.9490081045105551,  \n",
    "         33: 0.4986976082410339,  \n",
    "         34: 0.3433483134653754,  \n",
    "         35: 0.1178546620531288,  \n",
    "         36: -0.1117369964151409,  \n",
    "         37: -0.2143093785778471,  \n",
    "         38: -0.6099959110560267\n",
    "    }}).set_index(['feature_name'])\n",
    "\n",
    "# Факторы для модели ИП\n",
    "short_list = ['cred_hist', 'cnt_month_from_last', 'cnt_prod_7_730', 'cnt_receive_730', 'cnt_dpd_A_90', 'cnt_dpd_A_730']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для корректной работы\n",
    "df_ip['cred_hist'] = df_ip['cred_hist'].astype('int64')\n",
    "\n",
    "# Исключение по короткому списку\n",
    "bucket_summary = bucket_summary.loc[short_list]\n",
    "\n",
    "features = bucket_summary.index.get_level_values(0).unique()\n",
    "\n",
    "# Цикл для присвоения woe для наблюдений\n",
    "for fn in features: \n",
    "    first = True\n",
    "    n_bins = bucket_summary.loc[fn].shape[0]\n",
    "    \n",
    "    if df_ip.dtypes[fn] != object:\n",
    "  \n",
    "        for j in range(n_bins):\n",
    "            l, r, woe = bucket_summary.loc[fn][['left', 'right_incl', 'WOE']].iloc[j]\n",
    "            if first:\n",
    "                df_ip[fn+'_woe'] = np.nan\n",
    "                df_ip.iloc[np.where(df_ip[fn] <= r)[0], df_ip.columns.get_loc(fn+'_woe')] = woe\n",
    "            elif j == n_bins-1:\n",
    "                df_ip.iloc[np.where(df_ip[fn] > l)[0], df_ip.columns.get_loc(fn+'_woe')] = woe\n",
    "            else:\n",
    "                df_ip.iloc[np.where((df_ip[fn] > l) & (df_ip[fn] <= r))[0], df_ip.columns.get_loc(fn+'_woe')] = woe\n",
    "            first = False\n",
    "    \n",
    "    else:\n",
    "        for j in range(n_bins):\n",
    "            s, woe = bucket_summary.loc[fn][['bin_idx', 'WOE']].iloc[j]    \n",
    "            if first:\n",
    "                df_ip[fn+'_woe'] = np.nan    \n",
    "            df_ip.iloc[np.where(df_ip[fn] == s)[0], df_ip.columns.get_loc(fn+'_woe')] = woe    \n",
    "            first = False       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   6 out of   6 | elapsed:    1.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   6 out of   6 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "# Получение сглаженных woe\n",
    "def get_woe_smoothed(fn, bucket_summary, df_col, smooth = 6):\n",
    "\n",
    "    intervals = sorted(list(set(bucket_summary['left'].tolist() + bucket_summary['right_incl'].tolist())))\n",
    "    breaks = bucket_summary['right_incl'][:-1].tolist()\n",
    "    woes = bucket_summary['WOE'].tolist()\n",
    "\n",
    "    slopes = []\n",
    "    for i in range(len(intervals)-2):\n",
    "        slopes.append(min(intervals[i + 1] - intervals[i], intervals[i + 2] - intervals[i + 1]))\n",
    "    \n",
    "    res = []\n",
    "    for i in range(df_col.shape[0]):\n",
    "        y = woes[0]\n",
    "        for j in range(len(breaks)):\n",
    "            y += (woes[j + 1] - woes[j])/(1 + np.exp(smooth*(breaks[j] - df_col.iloc[i])/slopes[j]))   \n",
    "        res.append(y)      \n",
    "    return {fn+'_woe_smoothed': res}\n",
    "\n",
    "woe_list = Parallel(verbose = True, n_jobs = 4)(\n",
    "    delayed(get_woe_smoothed)(fn, bucket_summary.loc[fn], df_ip[fn], smooth = 6) for fn in features if df_ip[fn].dtype != np.object)\n",
    "\n",
    "# Заполнение исходной таблицы\n",
    "for i in range(len(woe_list)):\n",
    "    for k in woe_list[i]:\n",
    "        df_ip[k] = woe_list[i][k]\n",
    "\n",
    "del woe_list\n",
    "\n",
    "# Простановка скора \n",
    "df_ip['scor_IP'] = (-1) * (0.389 * df_ip['cred_hist_woe_smoothed'] + \n",
    "                           0.131 * df_ip['cnt_month_from_last_woe_smoothed'] + \n",
    "                           0.060 * df_ip['cnt_prod_7_730_woe_smoothed'] +\n",
    "                           0.124 * df_ip['cnt_dpd_A_90_woe_smoothed'] + \n",
    "                           0.142 * df_ip['cnt_receive_730_woe_smoothed'] + \n",
    "                           0.154 * df_ip['cnt_dpd_A_730_woe_smoothed'])  \n",
    "df_ip['scor_UL'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итоговый скор по модели ЮЛ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Список факторов для модели ЮЛ**\n",
    "- *cnt_month_from_last* - Количество месяцев от взятия последнего кредита\n",
    "- *cnt_active_90* - Количество активных кредитов за 3 месяцев\n",
    "- *cnt_dpd_A_730* - Количество просрочек 1-29 за 2 года \n",
    "- *cnt_dpd_A_90* - Количество просрочек 1-29 за 3 месяца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основные параметры WOE трансформации\n",
    "bucket_summary = pd.DataFrame.from_dict(\n",
    "    {'feature_name': {\n",
    "        0: 'cnt_active_90',  \n",
    "        1: 'cnt_active_90',  \n",
    "        2: 'cnt_active_90',  \n",
    "        3: 'cnt_active_90',  \n",
    "        4: 'cnt_active_90',  \n",
    "        5: 'cnt_active_90',  \n",
    "        6: 'cnt_dpd_2_730', \n",
    "        7: 'cnt_dpd_2_730',  \n",
    "        8: 'cnt_dpd_2_730',  \n",
    "        9: 'cnt_dpd_A_180',  \n",
    "        10: 'cnt_dpd_A_180',  \n",
    "        11: 'cnt_dpd_A_730',  \n",
    "        12: 'cnt_dpd_A_730',  \n",
    "        13: 'cnt_dpd_A_730',  \n",
    "        14: 'cnt_dpd_A_730',  \n",
    "        15: 'cnt_dpd_A_730',  \n",
    "        16: 'cnt_dpd_A_90',  \n",
    "        17: 'cnt_dpd_A_90',  \n",
    "        18: 'cnt_month_from_last',  \n",
    "        19: 'cnt_month_from_last',  \n",
    "        20: 'cnt_month_from_last',  \n",
    "        21: 'cnt_month_from_last',  \n",
    "        22: 'cnt_month_from_last'}, \n",
    "     'bin_idx': {\n",
    "         0: 0,  1: 1,  2: 2,  3: 3,  4: 4,  5: 5,  \n",
    "         6: 0,  7: 1,  8: 2,  \n",
    "         9: 0,  10: 1,  \n",
    "         11: 0,  12: 1,  13: 2,  14: 3,  15: 4,  \n",
    "         16: 0,  17: 1,  \n",
    "         18: 0,  19: 1,  20: 2,  21: 3,  22: 4}, \n",
    "     'left': {\n",
    "         0: 1.0,  1: 1.5,  2: 2.5,  3: 3.5,  4: 7.5,  5: 9.5,  \n",
    "         6: 0.0,  7: 0.5,  8: 1.5,  \n",
    "         9: 0.0,  10: 0.5,  \n",
    "         11: 0.0,  12: 0.5,  13: 1.5,  14: 2.5,  15: 3.5,  \n",
    "         16: 0.0,  17: 0.5,  \n",
    "         18: 0.0,  19: 0.5,  20: 3.5,  21: 9.5,  22: 29.5}, \n",
    "     'right_incl': {\n",
    "         0: 1.5,  1: 2.5,  2: 3.5,  3: 7.5,  4: 9.5,  5: 79.0,  \n",
    "         6: 0.5,  7: 1.5,  8: 25.0,  \n",
    "         9: 0.5,  10: 51.0,  \n",
    "         11: 0.5,  12: 1.5,  13: 2.5,  14: 3.5,  15: 51.0,  \n",
    "         16: 0.5,  17: 51.0,  \n",
    "         18: 0.5,  19: 3.5,  20: 9.5,  21: 29.5,  22: 208.0}, \n",
    "     'WOE': {\n",
    "         0: -1.158132441472729,  \n",
    "         1: -0.5315137995933312,  \n",
    "         2: -0.2627483944178875,  \n",
    "         3: 0.2141040418688166,  \n",
    "         4: 0.6427225932398114,  \n",
    "         5: 1.163942338742966,  \n",
    "         6: -0.0520265220091672,  \n",
    "         7: 1.39747105357057,  \n",
    "         8: 2.420450090528559,  \n",
    "         9: -0.3894153462139236,  \n",
    "         10: 1.450477369113718,  \n",
    "         11: -0.4755581616314268,  \n",
    "         12: 0.4970329566102819,  \n",
    "         13: 1.015267444888463,  \n",
    "         14: 1.211165772793313,  \n",
    "         15: 1.763044832651433,  \n",
    "         16: -0.3322601101120781,  \n",
    "         17: 1.715397677852292,  \n",
    "         18: 0.6532057423529526,  \n",
    "         19: 0.2176378854008926,  \n",
    "         20: -0.03165928484385846,  \n",
    "         21: -0.432403260781111,  \n",
    "         22: -1.171514636313427}}).set_index(['feature_name'])\n",
    "\n",
    "# Факторы для модели ЮЛ\n",
    "short_list = ['cnt_month_from_last', 'cnt_active_90', 'cnt_dpd_A_730', 'cnt_dpd_A_90']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_summary = bucket_summary.loc[short_list]\n",
    "features = bucket_summary.index.get_level_values(0).unique()\n",
    "\n",
    "# Цикл для присвоения woe для наблюдений (обязательно соблюдение сортировки!)\n",
    "\n",
    "for fn in features:\n",
    "    first = True\n",
    "    n_bins = bucket_summary.loc[fn].shape[0]\n",
    "    if df_ul.dtypes[fn] != object:   \n",
    "        for j in range(n_bins):\n",
    "            l, r, woe = bucket_summary.loc[fn][['left', 'right_incl', 'WOE']].iloc[j]\n",
    "            if first:\n",
    "                df_ul[fn+'_woe'] = np.nan\n",
    "                df_ul.iloc[np.where(df_ul[fn] <= r)[0], df_ul.columns.get_loc(fn+'_woe')] = woe\n",
    "            elif j == n_bins-1:\n",
    "                df_ul.iloc[np.where(df_ul[fn] > l)[0], df_ul.columns.get_loc(fn+'_woe')] = woe\n",
    "            else:\n",
    "                df_ul.iloc[np.where((df_ul[fn] > l) & (df_ul[fn] <= r))[0], df_ul.columns.get_loc(fn+'_woe')] = woe\n",
    "            first = False \n",
    "    else:     \n",
    "        for j in range(n_bins):\n",
    "            s, woe = bucket_summary.loc[fn][['bin_idx', 'WOE']].iloc[j]   \n",
    "            if first:\n",
    "                df_ul[fn+'_woe'] = np.nan            \n",
    "            df_ul.iloc[np.where(df_ul[fn] == s)[0], df_ul.columns.get_loc(fn+'_woe')] = woe           \n",
    "            first = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    1.4s remaining:    1.4s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    1.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Получение сглаженных woe\n",
    "def get_woe_smoothed(fn, bucket_summary, df_col, smooth = 6):\n",
    "    # расчет вспомогательных массивов\n",
    "    intervals = sorted(list(set(bucket_summary['left'].tolist() + bucket_summary['right_incl'].tolist())))\n",
    "    breaks = bucket_summary['right_incl'][:-1].tolist()\n",
    "    woes = bucket_summary['WOE'].tolist()\n",
    "    \n",
    "    slopes = []\n",
    "    for i in range(len(intervals)-2):\n",
    "        slopes.append(min(intervals[i + 1] - intervals[i], intervals[i + 2] - intervals[i + 1]))\n",
    "    \n",
    "    res = []\n",
    "\n",
    "    for i in range(df_col.shape[0]):\n",
    "        y = woes[0]\n",
    "        for j in range(len(breaks)):\n",
    "            y += (woes[j + 1] - woes[j])/(1 + np.exp(smooth*(breaks[j] - df_col.iloc[i])/slopes[j]))      \n",
    "        res.append(y)\n",
    "        \n",
    "    return {fn+'_woe_smoothed': res}\n",
    "\n",
    "woe_list = Parallel(verbose = True, n_jobs = 4)(\n",
    "    delayed(get_woe_smoothed)(fn, bucket_summary.loc[fn], df_ul[fn], smooth = 6) for fn in features if df_ul[fn].dtype != np.object)\n",
    "\n",
    "# Заполнение исходной таблицы\n",
    "for i in range(len(woe_list)):\n",
    "    for k in woe_list[i]:\n",
    "        df_ul[k] = woe_list[i][k]\n",
    "\n",
    "del woe_list\n",
    "\n",
    "# Простановка скора \n",
    "df_ul['scor_UL'] = (-1) * (0.328 * df_ul['cnt_month_from_last_woe_smoothed'] + \n",
    "                           0.183 * df_ul['cnt_dpd_A_90_woe_smoothed'] + \n",
    "                           0.197 * df_ul['cnt_active_90_woe_smoothed'] + \n",
    "                           0.292 * df_ul['cnt_dpd_A_730_woe_smoothed'])  \n",
    "df_ul['scor_IP'] = np.nan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итоговый скор по модели связанных ФЛ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Список факторов для модели связанных ФЛ**\n",
    "- *cnt_dpd_A_180_max_lvl1* - Максимальное количество просрочек 1-29 за 6 месяцев среди связанных лиц 1-ого уровня\n",
    "- *cnt_active_365_max_lvl1* - Максимальное количество активных кредитов за 1 год среди среди связанных лиц 1-ого уровня\n",
    "- *cnt_prod_9_365_sum_lvl1* - Количество взятых потребительских кредитов за 1 год среди среди связанных лиц 1-ого уровня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_summary = pd.DataFrame.from_dict({\n",
    "    'feature_name': {\n",
    "        0: 'cnt_active_365_max_lvl1',  \n",
    "        1: 'cnt_active_365_max_lvl1',  \n",
    "        2: 'cnt_active_365_max_lvl1',  \n",
    "        3: 'cnt_active_365_max_lvl1',  \n",
    "        4: 'cnt_dpd_2_730_max_lvl1',  \n",
    "        5: 'cnt_dpd_2_730_max_lvl1',  \n",
    "        6: 'cnt_dpd_2_730_max_lvl1',  \n",
    "        7: 'cnt_dpd_2_730_max_lvl1',  \n",
    "        8: 'cnt_dpd_3_730_max_lvl1',  \n",
    "        9: 'cnt_dpd_3_730_max_lvl1',  \n",
    "        10: 'cnt_dpd_3_730_max_lvl1',  \n",
    "        11: 'cnt_dpd_A_180_max_lvl1',  \n",
    "        12: 'cnt_dpd_A_180_max_lvl1',  \n",
    "        13: 'cnt_dpd_A_180_max_lvl1',  \n",
    "        14: 'cnt_dpd_A_180_max_lvl1',  \n",
    "        15: 'cnt_dpd_A_180_max_lvl1',  \n",
    "        16: 'cnt_dpd_A_730_max_lvl1',  \n",
    "        17: 'cnt_dpd_A_730_max_lvl1',  \n",
    "        18: 'cnt_dpd_A_730_max_lvl1',  \n",
    "        19: 'cnt_dpd_A_730_max_lvl1',  \n",
    "        20: 'cnt_dpd_A_730_max_lvl1', \n",
    "        21: 'cnt_prod_7_730_sum_lvl1',  \n",
    "        22: 'cnt_prod_7_730_sum_lvl1',  \n",
    "        23: 'cnt_prod_7_730_sum_lvl1',  \n",
    "        24: 'cnt_prod_7_730_sum_lvl1',  \n",
    "        25: 'cnt_prod_9_365_sum_lvl1',  \n",
    "        26: 'cnt_prod_9_365_sum_lvl1',  \n",
    "        27: 'cnt_prod_9_365_sum_lvl1',  \n",
    "        28: 'cnt_prod_9_365_sum_lvl1',\n",
    "        29: 'has_stop',  \n",
    "        30: 'has_stop'}, \n",
    "    'bin_idx': {\n",
    "        0: 0,  1: 1,  2: 2,  3: 3,  \n",
    "        4: 0,  5: 1,  6: 2,  7: 3,  \n",
    "        8: 0,  9: 1,  10: 2,  \n",
    "        11: 0,  12: 1,  13: 2,  14: 3,  15: 4,  \n",
    "        16: 0,  17: 1,  18: 2,  19: 3,  20: 4,  \n",
    "        21: 0,  22: 1,  23: 2,  24: 3,  \n",
    "        25: 0,  26: 1,  27: 2,  28: 3,  \n",
    "        29: 0,  30: 1}, \n",
    "    'left': {\n",
    "        0: 0.0,  1: 3.5,  2: 6.5,  3: 11.5,  \n",
    "        4: 0.0,  5: 0.5,  6: 1.5,  7: 2.5,  \n",
    "        8: 0.0,  9: 0.5,  10: 1.5,  \n",
    "        11: 0.0,  12: 0.5,  13: 1.5,  14: 3.5,  15: 6.5,  \n",
    "        16: 0.0,  17: 4.5,  18: 6.5,  19: 9.5,  20: 20.5,  \n",
    "        21: 0.0,  22: 1.5,  23: 2.5,  24: 3.5,  \n",
    "        25: 0.0,  26: 0.5,  27: 1.5,  28: 2.5,  \n",
    "        29: 0.0,  30: 0.5}, \n",
    "    'right_incl': {\n",
    "        0: 3.5,  1: 6.5,  2: 11.5,  3: 80.0,  \n",
    "        4: 0.5,  5: 1.5,  6: 2.5,  7: 32.0,  \n",
    "        8: 0.5,  9: 1.5,  10: 26.0,  \n",
    "        11: 0.5,  12: 1.5,  13: 3.5,  14: 6.5,  15: 37.0,  \n",
    "        16: 4.5,  17: 6.5,  18: 9.5,  19: 20.5,  20: 112.0,  \n",
    "        21: 1.5,  22: 2.5,  23: 3.5,  24: 30.0,  \n",
    "        25: 0.5,  26: 1.5,  27: 2.5,  28: 20.0,  \n",
    "        29: 0.5,  30: 1.0}, \n",
    "    'WOE': {\n",
    "        0: -0.6256251932854481,  \n",
    "        1: -0.1176781186831952,  \n",
    "        2: 0.5457381360852023, \n",
    "        3: 1.143206535960513,  \n",
    "        4: -0.192264395736754,  \n",
    "        5: 0.4732417562567837,  \n",
    "        6: 0.9840951651327359,  \n",
    "        7: 0.9649148320616778,  \n",
    "        8: -0.1154409230101402, \n",
    "        9: 0.9236873078891482,  \n",
    "        10: 1.043578520753722,  \n",
    "        11: -0.5798446977457254,  \n",
    "        12: -0.1150273236840405,  \n",
    "        13: 0.4553007149170635,  \n",
    "        14: 0.831819873555477,  \n",
    "        15: 1.425927917411775,  \n",
    "        16: -0.4631818850718804,  \n",
    "        17: 0.3588462915572382,  \n",
    "        18: 0.5225325512821059,  \n",
    "        19: 0.7097430687848124,  \n",
    "        20: 1.214708281606444,  \n",
    "        21: -0.240617232575307,  \n",
    "        22: 0.3078052739691285,  \n",
    "        23: 0.6456149501959487,  \n",
    "        24: 0.8771931072997814,  \n",
    "        25: -0.4129520653637384,  \n",
    "        26: -0.02328795978823093,  \n",
    "        27: 0.2307368421916449,  \n",
    "        28: 1.107425272186402,  \n",
    "        29: -0.1987155685653694,  \n",
    "        30: 0.8048807306899775}}).set_index(['feature_name'])\n",
    "\n",
    "# Факторы для модели по связанным ФЛ \n",
    "short_list = ['cnt_dpd_A_180_max_lvl1', 'cnt_active_365_max_lvl1', 'cnt_prod_9_365_sum_lvl1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_summary = bucket_summary.loc[short_list]\n",
    "features = bucket_summary.index.get_level_values(0).unique()\n",
    "\n",
    "# цикл для присвоения woe для наблюдений (обязательно соблюдение сортировки!)\n",
    "for fn in features:\n",
    "    \n",
    "    first = True\n",
    "    n_bins = bucket_summary.loc[fn].shape[0]\n",
    "    \n",
    "    if df1.dtypes[fn] != object:\n",
    "        \n",
    "        for j in range(n_bins):\n",
    "            l, r, woe = bucket_summary.loc[fn][['left', 'right_incl', 'WOE']].iloc[j]\n",
    "            if first:\n",
    "                df1[fn+'_woe'] = np.nan\n",
    "                df1.iloc[np.where(df1[fn] <= r)[0], df1.columns.get_loc(fn+'_woe')] = woe\n",
    "            elif j == n_bins-1:\n",
    "                df1.iloc[np.where(df1[fn] > l)[0], df1.columns.get_loc(fn+'_woe')] = woe\n",
    "            else:\n",
    "                df1.iloc[np.where((df1[fn] > l) & (df1[fn] <= r))[0], df1.columns.get_loc(fn+'_woe')] = woe\n",
    "            first = False\n",
    "    \n",
    "    else:        \n",
    "        for j in range(n_bins):\n",
    "            s, woe = bucket_summary.loc[fn][['bin_idx', 'WOE']].iloc[j]            \n",
    "            if first:\n",
    "                df1[fn+'_woe'] = np.nan            \n",
    "            df1.iloc[np.where(df1[fn] == s)[0], df1.columns.get_loc(fn+'_woe')] = woe           \n",
    "            first = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   3 | elapsed:    1.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Получение сглаженных woe\n",
    "def get_woe_smoothed(fn, bucket_summary, df_col, smooth = 6):\n",
    "    # расчет вспомогательных массивов\n",
    "    intervals = sorted(list(set(bucket_summary['left'].tolist() + bucket_summary['right_incl'].tolist())))\n",
    "    breaks = bucket_summary['right_incl'][:-1].tolist()\n",
    "    woes = bucket_summary['WOE'].tolist()\n",
    "    \n",
    "    slopes = []\n",
    "    for i in range(len(intervals)-2):\n",
    "        slopes.append(min(intervals[i + 1] - intervals[i], intervals[i + 2] - intervals[i + 1]))\n",
    "    \n",
    "    res = []\n",
    "\n",
    "    for i in range(df_col.shape[0]):\n",
    "        y = woes[0]\n",
    "        for j in range(len(breaks)):\n",
    "            y += (woes[j + 1] - woes[j])/(1 + np.exp(smooth*(breaks[j] - df_col.iloc[i])/slopes[j]))      \n",
    "        res.append(y)\n",
    "        \n",
    "    return {fn+'_woe_smoothed': res}\n",
    "\n",
    "woe_list = Parallel(verbose = True, n_jobs = 4)(\n",
    "    delayed(get_woe_smoothed)(fn, bucket_summary.loc[fn], df1[fn], smooth = 6) for fn in features if df1[fn].dtype != np.object)\n",
    "\n",
    "# заполнение исходной таблицы\n",
    "for i in range(len(woe_list)):\n",
    "    for k in woe_list[i]:\n",
    "        df1[k] = woe_list[i][k]\n",
    "\n",
    "del woe_list\n",
    "# простановка скора \n",
    "df1['scor_con'] = (-1) * (0.398 * df1['cnt_dpd_A_180_max_lvl1_woe_smoothed'] + \n",
    "                          0.327 * df1['cnt_active_365_max_lvl1_woe_smoothed'] + \n",
    "                          0.275 * df1['cnt_prod_9_365_sum_lvl1_woe_smoothed'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в конце можно объединить эти 2 df\n",
    "if len(df_ul) == 0:\n",
    "    add_row = {'inn_con': 'delete',\n",
    "                 'application_date': pd.to_datetime(dt.date(2012, 10, 14)),\n",
    "                 'con_lvl': 0,\n",
    "                 'inn': '7839481330',\n",
    "                 'cred_hist': 20,\n",
    "                 'cnt_month_from_last': 8,\n",
    "                 'cnt_prod_7_365': 0,\n",
    "                 'cnt_prod_7_730': 0,\n",
    "                 'cnt_prod_9_365': 0,\n",
    "                 'cnt_prod_9_730': 0,\n",
    "                 'cnt_dpd_2_90': 0,\n",
    "                 'cnt_dpd_2_180': 0,\n",
    "                 'cnt_dpd_2_365': 0,\n",
    "                 'cnt_dpd_2_730': 0,\n",
    "                 'cnt_dpd_3_90': 0,\n",
    "                 'cnt_dpd_3_180': 0,\n",
    "                 'cnt_dpd_3_365': 0,\n",
    "                 'cnt_dpd_3_730': 0,\n",
    "                 'cnt_dpd_A_90': 0,\n",
    "                 'cnt_dpd_A_180': 0,\n",
    "                 'cnt_dpd_A_365': 0,\n",
    "                 'cnt_dpd_A_730': 0,\n",
    "                 'cnt_receive_365': 2,\n",
    "                 'cnt_receive_730': 3,\n",
    "                 'cnt_active_90': 2,\n",
    "                 'cnt_active_180': 2,\n",
    "                 'cnt_active_365': 2,\n",
    "                 'ul_flag': 1,\n",
    "                 'cnt_month_from_last_woe': -0.03165928484385846,\n",
    "                 'cnt_active_90_woe': -0.5315137995933312,\n",
    "                 'cnt_dpd_A_730_woe': -0.4755581616314268,\n",
    "                 'cnt_dpd_A_90_woe': -0.3322601101120781,\n",
    "                 'cnt_month_from_last_woe_smoothed': -0.1059007911381904,\n",
    "                 'cnt_active_90_woe_smoothed': -0.5202578869890843,\n",
    "                 'cnt_dpd_A_730_woe_smoothed': -0.4730893026413821,\n",
    "                 'cnt_dpd_A_90_woe_smoothed': -0.3271970240486939,\n",
    "                 'scor_UL': 0.3352453950023706,\n",
    "                 'scor_IP': np.nan}\n",
    "    add_df = pd.DataFrame(add_row, index=[0])\n",
    "    df_ul = pd.concat([df_ul, add_df], axis=0, sort = False, ignore_index=True)\n",
    "\n",
    "if len(df_ip) == 0:\n",
    "    add_row = {'inn_con': 'delete',\n",
    "                 'application_date': pd.to_datetime(dt.date(2012, 10, 14)),\n",
    "                 'con_lvl': 0,\n",
    "                 'inn': '784000211707',\n",
    "                 'cred_hist': 38,\n",
    "                 'cnt_month_from_last': 4,\n",
    "                 'cnt_prod_7_365': 3,\n",
    "                 'cnt_prod_7_730': 4,\n",
    "                 'cnt_prod_9_365': 1,\n",
    "                 'cnt_prod_9_730': 1,\n",
    "                 'cnt_dpd_2_90': 0,\n",
    "                 'cnt_dpd_2_180': 0,\n",
    "                 'cnt_dpd_2_365': 0,\n",
    "                 'cnt_dpd_2_730': 0,\n",
    "                 'cnt_dpd_3_90': 0,\n",
    "                 'cnt_dpd_3_180': 0,\n",
    "                 'cnt_dpd_3_365': 0,\n",
    "                 'cnt_dpd_3_730': 0,\n",
    "                 'cnt_dpd_A_90': 0,\n",
    "                 'cnt_dpd_A_180': 0,\n",
    "                 'cnt_dpd_A_365': 0,\n",
    "                 'cnt_dpd_A_730': 0,\n",
    "                 'cnt_receive_365': 5,\n",
    "                 'cnt_receive_730': 6,\n",
    "                 'cnt_active_90': 7,\n",
    "                 'cnt_active_180': 7,\n",
    "                 'cnt_active_365': 7,\n",
    "                 'ul_flag': 0,\n",
    "                 'cred_hist_woe': 0.1178546620531288,\n",
    "                 'cnt_month_from_last_woe': 0.06880121494737351,\n",
    "                 'cnt_prod_7_730_woe': 1.043458213387425,\n",
    "                 'cnt_receive_730_woe': 0.5941197331040289,\n",
    "                 'cnt_dpd_A_90_woe': -0.5866946449965996,\n",
    "                 'cnt_dpd_A_730_woe': -0.8099897567938716,\n",
    "                 'cred_hist_woe_smoothed': 0.1069031596218363,\n",
    "                 'cnt_month_from_last_woe_smoothed': 0.0764295729576305,\n",
    "                 'cnt_prod_7_730_woe_smoothed': 1.0433655821589392,\n",
    "                 'cnt_receive_730_woe_smoothed': 0.5866958332510841,\n",
    "                 'cnt_dpd_A_90_woe_smoothed': -0.5834495608780129,\n",
    "                 'cnt_dpd_A_730_woe_smoothed': -0.807769114154907,\n",
    "                 'scor_IP': -0.0007661572728049071,\n",
    "                 'scor_UL': np.nan}\n",
    "    add_df = pd.DataFrame(add_row, index=[0])\n",
    "    df_ip = pd.concat([df_ip, add_df], axis=0, sort = False, ignore_index=True)\n",
    "\n",
    "df = pd.concat([df_ul, df_ip] , sort = False, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохранение выходных данных в csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для связей 0-ого уровня, мэтчим со стоп сигналами\n",
    "df = df.merge(df_stop[['inn', 'stop_count_cred_lvl0', 'stop_CURRENTDELQ_max_lvl0', 'stop_cnt_dpd_2_730_max_lvl0', 'stop_cnt_dpd_3_730_max_lvl0',\n",
    "                       'stop_has_90_lvl0', 'stop_ul_name', 'stop_ip_name', 'stop_bki_ip', 'stop_bki_ul', 'stop_bki_final']], \n",
    "                       on=['inn'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для связей 1-ого уровня, мэтчим со стоп сигналами\n",
    "df1 = df1.merge(df_stop[['inn', 'stop_CURRENTDELQ_max_lvl1', 'stop_cnt_dpd_3_730_max_lvl1', \n",
    "                         'stop_cnt_dpd_2_730_max_lvl1', 'stop_count_cred_lvl1', 'stop_cnt_dpd_A_730_max_lvl1',\n",
    "                         'stop_has_90_lvl1','stop_ul_name', 'stop_ip_name', 'stop_bki_ip', 'stop_bki_ul', 'stop_bki_final']], \n",
    "                          on=['inn'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col = ['inn','application_date', 'con_lvl', 'ul_flag', \n",
    "          'stop_count_cred_lvl0', 'stop_CURRENTDELQ_max_lvl0', 'stop_cnt_dpd_2_730_max_lvl0', 'stop_cnt_dpd_3_730_max_lvl0',\n",
    "          'stop_has_90_lvl0',  'stop_ul_name', 'stop_ip_name', 'stop_bki_ip', 'stop_bki_ul', 'stop_bki_final',\n",
    "          'cred_hist', 'cnt_month_from_last', 'cnt_prod_7_730', 'cnt_receive_730', 'cnt_dpd_A_90', 'cnt_dpd_A_730', 'cnt_active_90',\n",
    "          'cred_hist_woe', 'cred_hist_woe_smoothed', 'cnt_month_from_last_woe', 'cnt_month_from_last_woe_smoothed', \n",
    "          'cnt_prod_7_730_woe', 'cnt_prod_7_730_woe_smoothed', 'cnt_receive_730_woe','cnt_receive_730_woe_smoothed',\n",
    "          'cnt_dpd_A_730_woe', 'cnt_dpd_A_730_woe_smoothed', 'cnt_dpd_A_90_woe', 'cnt_dpd_A_90_woe_smoothed',\n",
    "          'cnt_active_90_woe',  'cnt_active_90_woe_smoothed', 'scor_UL', 'scor_IP']\n",
    "\n",
    "df1_col = ['inn', 'application_date', 'con_lvl', 'stop_CURRENTDELQ_max_lvl1', 'stop_cnt_dpd_3_730_max_lvl1', \n",
    "            'stop_cnt_dpd_2_730_max_lvl1', 'stop_count_cred_lvl1', 'stop_cnt_dpd_A_730_max_lvl1',\n",
    "            'stop_has_90_lvl1', 'stop_ul_name', 'stop_ip_name', 'stop_bki_ip', 'stop_bki_ul', 'stop_bki_final',    \n",
    "            'cnt_dpd_A_180_max_lvl1', 'cnt_active_365_max_lvl1', 'cnt_prod_9_365_sum_lvl1','cnt_dpd_A_180_max_lvl1_woe', \n",
    "            'cnt_active_365_max_lvl1_woe','cnt_prod_9_365_sum_lvl1_woe', 'cnt_dpd_A_180_max_lvl1_woe_smoothed', \n",
    "            'cnt_active_365_max_lvl1_woe_smoothed', 'cnt_prod_9_365_sum_lvl1_woe_smoothed', 'scor_con']\n",
    "\n",
    "df2_col = ['inn', 'application_date', 'con_lvl', 'stop_CURRENTDELQ_max_lvl2','stop_cnt_dpd_3_730_max_lvl2',\\\n",
    "           'stop_cnt_dpd_2_730_max_lvl2','stop_count_cred_lvl2', 'stop_has_90_lvl2','stop_ul_name', 'stop_ip_name',\\\n",
    "           'stop_bki_ip', 'stop_bki_ul', 'stop_bki_final']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Костыль - переименовываем название полей т.к. GD не может этого сделать так как поломает все ETL процессы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df_col]\n",
    "df1 = df1[df1_col]\n",
    "df2 = df2[df2_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'stop_has_90_lvl0' : 'has_stop', \n",
    "                   'stop_count_cred_lvl0' : 'count_cred',\n",
    "                   'stop_CURRENTDELQ_max_lvl0' : 'CURRENTDELQ', \n",
    "                   'stop_cnt_dpd_2_730_max_lvl0' : 'cnt_dpd_2_730',\n",
    "                   'stop_cnt_dpd_3_730_max_lvl0' : 'cnt_dpd_3_730'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns={'stop_has_90_lvl1' : 'has_stop_max_lvl1', \n",
    "                    'stop_cnt_dpd_A_730_max_lvl1' : 'cnt_dpd_A_730_max_lvl1',\n",
    "                    'stop_cnt_dpd_2_730_max_lvl1' : 'cnt_dpd_2_730_max_lvl1', \n",
    "                    'stop_cnt_dpd_3_730_max_lvl1' : 'cnt_dpd_3_730_max_lvl1',\n",
    "                    'stop_CURRENTDELQ_max_lvl1' : 'CURRENTDELQ_max_lvl1',\n",
    "                    'stop_count_cred_lvl1' : 'count_cred_max_lvl1'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.rename(columns={'stop_cnt_dpd_2_730_max_lvl2' : 'cnt_dpd_2_730_max_lvl2',\n",
    "                    'stop_has_90_lvl2' : 'has_stop_max_lvl2',\n",
    "                    'stop_cnt_dpd_3_730_max_lvl2' : 'cnt_dpd_3_730_max_lvl2',\n",
    "                    'stop_CURRENTDELQ_max_lvl2' : 'CURRENTDELQ_max_lvl2',\n",
    "                    'stop_count_cred_lvl2' : 'count_cred_max_lvl2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохраняем итоговый результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates().to_csv(os.getenv('RES_LVL'), encoding='cp1251', sep = ';', index=False)\n",
    "df1.drop_duplicates().to_csv(os.getenv('RES_LVL1'), encoding='cp1251', sep = ';', index=False)\n",
    "df2.drop_duplicates().to_csv(os.getenv('RES_LVL2'), encoding='cp1251', sep = ';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop_duplicates().to_csv('RES_LVL.csv', encoding='cp1251', sep = ';', index=False)\n",
    "# df1.drop_duplicates().to_csv('RES_LVL1.csv', encoding='cp1251', sep = ';', index=False)\n",
    "# df2.drop_duplicates().to_csv('RES_LVL2.csv', encoding='cp1251', sep = ';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
